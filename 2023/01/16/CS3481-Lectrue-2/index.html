<!DOCTYPE html><html lang="zh-HK"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.8.0" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.8.0" type="image/png" sizes="32x32"><meta name="description" content="Data        A data set can often be viewed as a collection of data objects">
<meta property="og:type" content="article">
<meta property="og:title" content="CS3481-Lectrue-2">
<meta property="og:url" content="https://lemonkai.github.io/2023/01/16/CS3481-Lectrue-2/index.html">
<meta property="og:site_name" content="KAI Blog">
<meta property="og:description" content="Data        A data set can often be viewed as a collection of data objects">
<meta property="og:locale" content="zh_HK">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204155.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204114.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204047.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204028.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204006.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130203948.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130203926.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130203904.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130203800.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130203737.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204357.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204426.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130205356.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130205427.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130210104.png">
<meta property="article:published_time" content="2023-01-16T11:37:14.000Z">
<meta property="article:modified_time" content="2023-02-06T11:24:19.649Z">
<meta property="article:author" content="KAI">
<meta property="article:tag" content="CS3481">
<meta property="article:tag" content="Fundamental Data Science">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204155.png"><title>CS3481-Lectrue-2 | KAI Blog</title><link ref="canonical" href="https://lemonkai.github.io/2023/01/16/CS3481-Lectrue-2/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.8.0"><link rel="stylesheet" href="css/custom.css"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":false,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"複製","copySuccess":"複製成功","copyError":"複製失敗"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 6.3.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner header-inner--height header-inner--bgcolor"><nav class="header-nav header-nav--sticky"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首頁</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">歸檔</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">分類</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">標籤</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">CS3481-Lectrue-2</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">發表於</span><span class="post-meta-item__value">2023-01-16</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新於</span><span class="post-meta-item__value">2023-02-06</span></span></div></header><div class="post-body">
        <h1 id="Data"   >
          <a href="#Data" class="heading-link"><i class="fas fa-link"></i></a><a href="#Data" class="headerlink" title="Data"></a>Data</h1>
      <ul>
<li><p>A data set can often be viewed as a collection of data objects</p>
<span id="more"></span></li>
<li><p>Other names for a data object include recorde, point, vector, pattern, event, case, sample, observation or entity.</p>
</li>
<li><p>Data objects are described by a number of attributes that capture the basic charateristics of an object.</p>
</li>
<li><p>Other names for an attribute are variable, characteristic, field, featrue, or dimension.</p>
</li>
<li><p>A data set is usually a file, in which</p>
<blockquote>
<ul>
<li>The objects are records in the file and </li>
<li>Each field corresponds  to an attribute.</li>
</ul>
</blockquote>
</li>
</ul>

        <h1 id="Attribute"   >
          <a href="#Attribute" class="heading-link"><i class="fas fa-link"></i></a><a href="#Attribute" class="headerlink" title="Attribute"></a>Attribute</h1>
      <ul>
<li><p>An attribute is a property or characteristic of an object to another or from one time to another </p>
</li>
<li><p>A mesasurement scale is a rule that associates a numerical or symbolic value with an attribute of an object.</p>
</li>
<li><p>The process of mesurement is the application of a measurement scale to associate a value with a particular attribute of a specific object.</p>
</li>
</ul>

        <h1 id="Different-types-of-attributes"   >
          <a href="#Different-types-of-attributes" class="heading-link"><i class="fas fa-link"></i></a><a href="#Different-types-of-attributes" class="headerlink" title="Different types of attributes"></a>Different types of attributes</h1>
      <p>There define four types of attributes</p>
<blockquote>
<ul>
<li>Nominal</li>
<li>Ordinal</li>
<li>Interval</li>
<li>Ratio</li>
</ul>
</blockquote>
<ul>
<li><p>Nominal and orinal attributes are collectively referred to as categorical or quanlitative attributes.</p>
</li>
<li><p>Interval and ratio attributes are collectively referred to as quantitative or numeric attributes.</p>
</li>
</ul>

        <h2 id="Nominal"   >
          <a href="#Nominal" class="heading-link"><i class="fas fa-link"></i></a><a href="#Nominal" class="headerlink" title="Nominal"></a>Nominal</h2>
      <ul>
<li>values of a nominal attribute are just different names.</li>
<li>They provide only enough informatin ot distinguish one object from another.</li>
<li>Example: eye color, gender.</li>
</ul>

        <h2 id="Ordinal"   >
          <a href="#Ordinal" class="heading-link"><i class="fas fa-link"></i></a><a href="#Ordinal" class="headerlink" title="Ordinal"></a>Ordinal</h2>
      <ul>
<li>The values of an ordinal attribute provide enough information to odrder objects.</li>
<li>Example: grade</li>
</ul>

        <h2 id="Interval"   >
          <a href="#Interval" class="heading-link"><i class="fas fa-link"></i></a><a href="#Interval" class="headerlink" title="Interval"></a>Interval</h2>
      <ul>
<li>For interval attributes, the differences between values are meaningful.</li>
<li>Example: calendar dates.</li>
</ul>

        <h2 id="Ratio"   >
          <a href="#Ratio" class="heading-link"><i class="fas fa-link"></i></a><a href="#Ratio" class="headerlink" title="Ratio"></a>Ratio</h2>
      <ul>
<li><p>For ratio variables, both differences and ratios are meaningful</p>
</li>
<li><p>Example: monetaru quantities, mass, length</p>
</li>
<li><p>Another way to distinguish between attributes is by the number of values they can take.</p>
</li>
<li><p>Based on this criterion, attributes can be calssified as either discrete or continuous</p>
</li>
</ul>

        <h2 id="Discrete"   >
          <a href="#Discrete" class="heading-link"><i class="fas fa-link"></i></a><a href="#Discrete" class="headerlink" title="Discrete"></a>Discrete</h2>
      <ul>
<li><p>A discrete attribute has a finte or countably infinite set of values.</p>
</li>
<li><p>Such attributes can be categorical, such as gender, or numeric, such as counts.</p>
</li>
<li><p>Binary attributes are a special case of discrete attributes and assume only two values, e.g. true&#x2F;false, yes&#x2F;no, male&#x2F;female, or 0&#x2F;1</p>
</li>
</ul>

        <h2 id="Continuous"   >
          <a href="#Continuous" class="heading-link"><i class="fas fa-link"></i></a><a href="#Continuous" class="headerlink" title="Continuous"></a>Continuous</h2>
      <ul>
<li><p>A continuous attribute is one whose values are real numbers</p>
</li>
<li><p>Examples include temperature, height or weight.</p>
</li>
<li><p>Continuous attributes are typically represented as floating point variables.</p>
</li>
</ul>

        <h1 id="Types-of-data-sets"   >
          <a href="#Types-of-data-sets" class="heading-link"><i class="fas fa-link"></i></a><a href="#Types-of-data-sets" class="headerlink" title="Types of data sets"></a>Types of data sets</h1>
      <p>Following different types of data sets</p>
<ul>
<li>Record data</li>
<li>Transacion or market basket data</li>
<li>Data matrix</li>
<li>Sparse data matrix</li>
</ul>
<p>[]!()</p>

        <h2 id="Record-data"   >
          <a href="#Record-data" class="heading-link"><i class="fas fa-link"></i></a><a href="#Record-data" class="headerlink" title="Record data"></a>Record data</h2>
      <ul>
<li><p>A data set is usually represented as a coleection of records</p>
</li>
<li><p>Each record consists of a fixed set of data fields</p>
</li>
<li><p>Record data is usually stored eirher in flat files or in relational database.</p>
</li>
</ul>

        <h2 id="Transaction-or-market-basket-data"   >
          <a href="#Transaction-or-market-basket-data" class="heading-link"><i class="fas fa-link"></i></a><a href="#Transaction-or-market-basket-data" class="headerlink" title="Transaction or market basket data"></a>Transaction or market basket data</h2>
      <ul>
<li>Transaction data is a special type of record data.</li>
<li>Each transaction involves a set of items</li>
<li>Example: the set of products purchased by a customer during one shopping trip constitues a transaction.</li>
</ul>

        <h2 id="Data-matrix"   >
          <a href="#Data-matrix" class="heading-link"><i class="fas fa-link"></i></a><a href="#Data-matrix" class="headerlink" title="Data matrix"></a>Data matrix</h2>
      <ul>
<li><p>If the data objects all have the same fixed set of numeric attributes, then they can be thought of as points in a multi-dimensional space.</p>
</li>
<li><p>This kind of data set can be interpreted as an m by n matrix where</p>
<ul>
<li>There are m rows, one for each object.</li>
<li>There are n cols, one for each attribute.</li>
</ul>
</li>
<li><p>Standard matrix operations can be applied to transform and mainipulate the data.</p>
</li>
</ul>

        <h2 id="Sparse-data-matrix"   >
          <a href="#Sparse-data-matrix" class="heading-link"><i class="fas fa-link"></i></a><a href="#Sparse-data-matrix" class="headerlink" title="Sparse data matrix"></a>Sparse data matrix</h2>
      <ul>
<li><p>A sparse data matrix is a special case of a data matrix in which there are a large number of  zeros in the matrix, and only the non-zero attribute values are important</p>
</li>
<li><p>Sparsity is an advantage because usually only the non-zero values need to be stored and manipulated.</p>
</li>
<li><p>This results in significant savings with respect to computation time and storage.</p>
</li>
<li><p>An examlple is cocument data.</p>
</li>
<li><p>A document can be represented as a term vector, where</p>
<ul>
<li>Each term is a component of the vector and</li>
<li>The value of each component is the number of times the corresponding term occurs in the document.</li>
</ul>
</li>
<li><p>This representation of a coleection of documents is often called a document-term matrix.</p>
</li>
</ul>

        <h2 id="Data-quality"   >
          <a href="#Data-quality" class="heading-link"><i class="fas fa-link"></i></a><a href="#Data-quality" class="headerlink" title="Data quality"></a>Data quality</h2>
      <ul>
<li><p>Precision</p>
<ul>
<li>The closeness of repeated measurements to ne another</li>
<li>This is often measured by the standard deviation of a set of values.</li>
</ul>
</li>
<li><p>Bias</p>
<ul>
<li>Asystematic variation of measurements from the quantity being measured.</li>
<li>This is measured by takingthe differents between <ul>
<li>the mean of the set of values and</li>
<li>the known value of the quantity being measured.</li>
</ul>
</li>
</ul>
</li>
<li><p>Suppose we have a standard laboratory weight with a mass of 1g.</p>
</li>
<li><p>We want to assess the precision and bias of our new laboratory scale.</p>
</li>
<li><p>We weight the mass five times, and obtain the values: {1.015, 0.990,1.013,1.001,0.986}</p>
</li>
<li><p>The mean of these values is 1.001</p>
</li>
<li><p>The bias is thus 0.001</p>
</li>
<li><p>The precision, as measured by the standard devation, is 0.013</p>
</li>
<li><p>Noise </p>
<ul>
<li>Noise is the random component of a measurement error.</li>
</ul>
</li>
<li><p>Outliers</p>
<ul>
<li>Data objects that, in some sense, have characteristics that are different from most of the other data objects in the data set.</li>
<li>Values of an attribute that are unusual with respect to the typical values of that attribute</li>
</ul>
</li>
</ul>

        <h2 id="Data-quality-Missing-values"   >
          <a href="#Data-quality-Missing-values" class="heading-link"><i class="fas fa-link"></i></a><a href="#Data-quality-Missing-values" class="headerlink" title="Data quality: Missing values"></a>Data quality: Missing values</h2>
      <ul>
<li><p>It is not unusual for an object to be missing one or more attribute values.</p>
</li>
<li><p>There are several strategies for dealing with missing data</p>
<ul>
<li>Eliminate data object</li>
<li>Estimate missing values</li>
</ul>
</li>
<li><p>Eliminate data object</p>
<ul>
<li>If a data set has only a few objects taht have missing attribute values, then it may be convenient to omit them.</li>
<li>However, even a partially specified data object contains some information.</li>
<li>If many objects have missing values, then a reliable analysis can be difficult ot impossible</li>
</ul>
</li>
<li><p>Estimate missing values</p>
<ul>
<li><p>A missing attribute value of a point can be estimated by the corresponding attribute values of the other points.</p>
</li>
<li><p>If the attribute is discrete, then the most commonly occuring attribute value can be used.</p>
</li>
<li><p>If the attribute is continuous, then the average attribute value of similar points is used.</p>
</li>
</ul>
</li>
</ul>

        <h2 id="Data-preprocessing"   >
          <a href="#Data-preprocessing" class="heading-link"><i class="fas fa-link"></i></a><a href="#Data-preprocessing" class="headerlink" title="Data preprocessing"></a>Data preprocessing</h2>
      <ul>
<li>There are a number of techniques for performing data preprocssing <ul>
<li>Aggregation</li>
<li>Sampling</li>
<li>Dimensionality reduction</li>
<li>Discretization</li>
<li>Normalization</li>
</ul>
</li>
</ul>

        <h3 id="Aggregation-聚合"   >
          <a href="#Aggregation-聚合" class="heading-link"><i class="fas fa-link"></i></a><a href="#Aggregation-聚合" class="headerlink" title="Aggregation(聚合)"></a>Aggregation(聚合)</h3>
      <ul>
<li>Aggreation is the combining of two or more objects into a single object. </li>
<li>There are several motivations for aggregation<ul>
<li>The smaller data sets resulting from agrreation require less memory and processing time.</li>
<li>Aggregation can also provide a high-level view of the data</li>
<li>Aggregate quantites, such as averages or totals, have less variability than the individual objects.</li>
</ul>
</li>
<li>A disadvantage of aggregation is the potential loss of interesting details.</li>
</ul>

        <h3 id="Sampling"   >
          <a href="#Sampling" class="heading-link"><i class="fas fa-link"></i></a><a href="#Sampling" class="headerlink" title="Sampling"></a>Sampling</h3>
      <ul>
<li><p>Sampling is the selction of a subset of the data objects to be analyzed.</p>
</li>
<li><p>Sometimes, it is too expensive or time consuming to process all the data.</p>
</li>
<li><p>Using a sampling algorithm can reduce the data size to a point where a better, but more computationally expensive algorithm can be used.</p>
</li>
<li><p>A sample is representative if it has approximately the same property as the original set of data.</p>
</li>
<li><p>The simplest type of sampling is uniform random sampling.</p>
</li>
<li><p>For this type of sampling, there is an equal probability of seecting any particular item.</p>
</li>
<li><p>There are two variations on random sampling</p>
<ul>
<li>Sampling without replacement</li>
<li>Sampling with replacement</li>
</ul>
</li>
<li><p>Sampling without relacement</p>
<ul>
<li>As each item is selected, it is removed from the set of all objects.</li>
</ul>
</li>
<li><p>Samepling with replacement</p>
<ul>
<li>Objects are not removed from the data set as they are selcted.</li>
<li>The same object can be picked more than once.</li>
</ul>
</li>
<li><p>Once a sampling technique has been selected, it is still necessary to choose the sample size.</p>
</li>
<li><p>For larger sample sizes</p>
<ul>
<li>The probaility that a sample will be representative will be increased.</li>
<li>However, much of the advantage of sampling will also be eliminated.</li>
</ul>
</li>
<li><p>For smaller sample sizes</p>
<ul>
<li>There may be a loss of important information</li>
</ul>
</li>
</ul>

        <h3 id="Dimensionality-reduction"   >
          <a href="#Dimensionality-reduction" class="heading-link"><i class="fas fa-link"></i></a><a href="#Dimensionality-reduction" class="headerlink" title="Dimensionality reduction"></a>Dimensionality reduction</h3>
      <ul>
<li>The dimensionality of a data set is the number of attributes that each object possesses.</li>
<li>It is usually more difficult to analyze high-dimensional data</li>
<li>An important preprocessing step is dimensionality reduction.</li>
<li>Dimensionality reduction has a number of advantages:<ul>
<li>It can eliminate irrelevant featrues and reduce noise.</li>
<li>It can lead to a more understandable model which involves fewer attributes.</li>
<li>It may allow the data to be more easily visualized.</li>
<li>The amount of time and memory required for proessing the data is reduced.</li>
</ul>
</li>
<li>The curse of dimensionality refers to the phenomenon that many types of data analysis become significantly harder as the number of dimensions increases.</li>
<li>As the number of dimensions increases, the data becomes increasingly sparse in the space that it occupies.</li>
<li>There may not be enoygh data objects to allow the reliable creation of a model that describes the set of objects.</li>
<li>There are a number of techniques for dimensionality reduction<ul>
<li>Feature transformation</li>
<li>Feature subset selection</li>
</ul>
</li>
<li>Feature transformation<ul>
<li>Feature transformation can be used to project data from a high-dimensional space to a low-dimensonal space.</li>
<li>Principal Component Analysis(PCA) is a feature transformation technique to find new attriubtes that are<ul>
<li>linear combinations of the original attributes.</li>
<li>capture the maximum amount of variation in the data.</li>
</ul>
</li>
</ul>
</li>
</ul>

        <h3 id="Feature-subset-selection"   >
          <a href="#Feature-subset-selection" class="heading-link"><i class="fas fa-link"></i></a><a href="#Feature-subset-selection" class="headerlink" title="Feature subset selection"></a>Feature subset selection</h3>
      <ul>
<li><p>Another way to reduce the number of dimentsions is to use only a subset of the features.</p>
</li>
<li><p>This approach is effective if redundant and irrelevant fetures are present.</p>
</li>
<li><p>Redundant features duplicate much or all of the information contained in one or more other attributes.</p>
</li>
<li><p>Irrelevant features contain almost no useful information for the task at hand.</p>
</li>
<li><p>The ideal approach to feature selection is to </p>
<ul>
<li>Try all possible subsets of freatures</li>
<li>Take the subset that produces the best result</li>
</ul>
</li>
<li><p>Since the number of subsets involving n attributes is 2^n, such an approach is impractical in most situations</p>
</li>
<li><p>There are three standard approaches to feature selection</p>
<ul>
<li>Embedded approaches</li>
<li>Filter approaches</li>
<li>Wrapper approaches</li>
</ul>
</li>
</ul>

        <h4 id="Embedded-approaches"   >
          <a href="#Embedded-approaches" class="heading-link"><i class="fas fa-link"></i></a><a href="#Embedded-approaches" class="headerlink" title="Embedded approaches"></a>Embedded approaches</h4>
      <ul>
<li>Feature selection occurs naturally as part of the algorithm</li>
<li>The algorithm itself decides which attributes to use and which to ignore</li>
</ul>

        <h4 id="Filter-approaches"   >
          <a href="#Filter-approaches" class="heading-link"><i class="fas fa-link"></i></a><a href="#Filter-approaches" class="headerlink" title="Filter approaches"></a>Filter approaches</h4>
      <ul>
<li>Features are selected before the algorithm is run</li>
<li>An evaluation measure is used to determine the goodness of a subset of attributes</li>
<li>This measure is independent of the current algorithm used</li>
</ul>

        <h4 id="Wrapper-approaches"   >
          <a href="#Wrapper-approaches" class="heading-link"><i class="fas fa-link"></i></a><a href="#Wrapper-approaches" class="headerlink" title="Wrapper approaches"></a>Wrapper approaches</h4>
      <ul>
<li>These methods use the target algorithm as a black box to find the best subset of attributes.</li>
<li>Typically, not all the possible subsets are considered</li>
</ul>

        <h2 id="Discretization"   >
          <a href="#Discretization" class="heading-link"><i class="fas fa-link"></i></a><a href="#Discretization" class="headerlink" title="Discretization"></a>Discretization</h2>
      <ul>
<li><p>In some cases, we prefer to use data with discrete attributes</p>
</li>
<li><p>It is thus necessary to transform a continous attribute into a discrete attribute</p>
</li>
<li><p>Transformation of a continuous attribute to a discrete attribute involves two subtasks</p>
<ul>
<li>Deciding how many possible discrete values to have</li>
<li>Determining how to map the values of the continuous atrribute to these discrete values</li>
</ul>
</li>
<li><p>In the first step </p>
<ul>
<li>The values of the coninuous attribute are first sorted</li>
<li>They are then divided into S intervals by specifying S-1 split points</li>
</ul>
</li>
<li><p>In the second step</p>
<ul>
<li>All the values in one interval are mapped to the same discrete value</li>
</ul>
</li>
</ul>

        <h2 id="Normalization"   >
          <a href="#Normalization" class="heading-link"><i class="fas fa-link"></i></a><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h2>
      <ul>
<li>The goal of normalization or standardization is to make an entire set of values have a particular property</li>
<li>Normalization is necssary to avoid the case where a variable with large values dominates the result of the calculation</li>
</ul>

        <h1 id="Similarity-and-dissimilarity"   >
          <a href="#Similarity-and-dissimilarity" class="heading-link"><i class="fas fa-link"></i></a><a href="#Similarity-and-dissimilarity" class="headerlink" title="Similarity and dissimilarity"></a>Similarity and dissimilarity</h1>
      <ul>
<li><p>The similarity between two objects is a numerical measure of the degree to which the two objects are alike </p>
</li>
<li><p>Similarities are higher for pairs of objects that are more alike</p>
</li>
<li><p>The dissimilarity between two objects is a numerical measure of the degree to which the two objects are different</p>
</li>
<li><p>Dissimilarityes are lower for more similar pairs of objects</p>
</li>
<li><p>Freuently, the term distance is used as a synonym for dissimilarity</p>
</li>
<li><p>The term proximity is used to refer to either similarity or dissimilarity</p>
</li>
</ul>

        <h2 id="Dissimilarity-between-attribute-values"   >
          <a href="#Dissimilarity-between-attribute-values" class="heading-link"><i class="fas fa-link"></i></a><a href="#Dissimilarity-between-attribute-values" class="headerlink" title="Dissimilarity between attribute values"></a>Dissimilarity between attribute values</h2>
      <ul>
<li>We consider the definition of dissimilarity measures for the following attribute types <ul>
<li>Nominal</li>
<li>Ordinal</li>
<li>Intervale&#x2F;Ratio</li>
</ul>
</li>
</ul>

        <h3 id="Nominal-1"   >
          <a href="#Nominal-1" class="heading-link"><i class="fas fa-link"></i></a><a href="#Nominal-1" class="headerlink" title="Nominal"></a>Nominal</h3>
      <ul>
<li>Nominal attributes only convey information about the distinctness of objects</li>
<li>All we can say is that two objects either have the same attribute value or not</li>
<li>As a result, dissimilarity is defined as<ul>
<li>0 if the attribute avlues match</li>
<li>1 otherwise</li>
</ul>
</li>
</ul>

        <h3 id="Ordinal-1"   >
          <a href="#Ordinal-1" class="heading-link"><i class="fas fa-link"></i></a><a href="#Ordinal-1" class="headerlink" title="Ordinal"></a>Ordinal</h3>
      <ul>
<li>For ordinal attributes, information about order should be taken into account</li>
<li>The values of the ordinal attribute are often mapped to successive integers</li>
<li>The dissimilarity can be defined by taking the absolute difference between these integers</li>
</ul>

        <h3 id="Interval-x2F-Ratio"   >
          <a href="#Interval-x2F-Ratio" class="heading-link"><i class="fas fa-link"></i></a><a href="#Interval-x2F-Ratio" class="headerlink" title="Interval&#x2F;Ratio"></a>Interval&#x2F;Ratio</h3>
      <ul>
<li>For interval or ratio attributes, the natural measure of dissimilarity between two objects is the absolute differece of their values</li>
</ul>

        <h1 id="Distance"   >
          <a href="#Distance" class="heading-link"><i class="fas fa-link"></i></a><a href="#Distance" class="headerlink" title="Distance"></a>Distance</h1>
      <ul>
<li>The Euclidean distance d between two points x and y is given by</li>
</ul>
<p><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204155.png"></p>
<ul>
<li><p>n is the number of dimensions</p>
</li>
<li><p>Xu and Yu are, respectively, the u-th attributes of x and y</p>
</li>
<li><p>The Euclidean distance measure is generalized by the Minkowski distance metric as follows:</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204114.png"></p>
<ul>
<li><p>Three most common examples of Minkowski distances are</p>
<ul>
<li>h&#x3D;1: City block distance(L1 norm)</li>
<li>h&#x3D;2: Euclidean distance(L2 norm)</li>
<li>h&#x3D;00: Supremum distance(Lmax norm), which is the maximum difference between any attribute of the objects</li>
</ul>
</li>
<li><p>A distance measure has some well-known properites</p>
<ul>
<li>Positivity<ul>
<li>d(x,y)&gt;&#x3D;0 for all x and y</li>
<li>d(x,y)&#x3D;0 if and only if x &#x3D;y</li>
</ul>
</li>
<li>Symmetry<ul>
<li>d(x,y)&#x3D;d(y,x) for all x and y</li>
</ul>
</li>
<li>Triangle inequality<ul>
<li>d(x,z)&lt;&#x3D;d(x,y)+d(y,z) for all points x,y,z</li>
</ul>
</li>
</ul>
</li>
<li><p>all attributes were treated eually when computing the distance</p>
</li>
<li><p>This is not desirable when some attributes are more important than others</p>
</li>
<li><p>To address these situations, the distance measure can be modified by weighting the contribution of each attribute:</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204047.png"></p>

        <h1 id="Summary-statistics"   >
          <a href="#Summary-statistics" class="heading-link"><i class="fas fa-link"></i></a><a href="#Summary-statistics" class="headerlink" title="Summary statistics"></a>Summary statistics</h1>
      <ul>
<li>Summary statisticss are quantities that capture various characterics of a large set of values using a small set of numbers</li>
<li>We consider the following summary statistics<ul>
<li>Relative frequency and the mode</li>
<li>Measure of location: mean and meadian</li>
<li>Measure of spread: range and variance</li>
</ul>
</li>
</ul>

        <h2 id="Realtive-frequency-and-the-mode"   >
          <a href="#Realtive-frequency-and-the-mode" class="heading-link"><i class="fas fa-link"></i></a><a href="#Realtive-frequency-and-the-mode" class="headerlink" title="Realtive frequency and the mode"></a>Realtive frequency and the mode</h2>
      <ul>
<li>Suppose we are given a discrete attribute x, which can take values{a1,..,as,…,as}, and a set of m objects</li>
<li>The relative frequency of a value as is defined as</li>
</ul>
<p><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204028.png"></p>
<ul>
<li>The mode of a discrete attribute is the value that has the highest relative frequency</li>
</ul>

        <h2 id="Mean"   >
          <a href="#Mean" class="heading-link"><i class="fas fa-link"></i></a><a href="#Mean" class="headerlink" title="Mean"></a>Mean</h2>
      <ul>
<li><p>We consider a set of m objects and an attribute x</p>
</li>
<li><p>Let {x1,…,xm} be the attribute values of x for these m objects</p>
</li>
<li><p>The mean is defined as follows:</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204006.png"></p>

        <h2 id="Median"   >
          <a href="#Median" class="heading-link"><i class="fas fa-link"></i></a><a href="#Median" class="headerlink" title="Median"></a>Median</h2>
      <ul>
<li>Let{x1,…,xm} represent the values of x after they have been sorted in non-decreasing order</li>
<li>Thus, x1&#x3D; xmin and xm &#x3D; xmax</li>
<li>The meadian is defined as follows:</li>
</ul>
<p><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130203948.png"></p>

        <h2 id="Mean-and-Median"   >
          <a href="#Mean-and-Median" class="heading-link"><i class="fas fa-link"></i></a><a href="#Mean-and-Median" class="headerlink" title="Mean and Median"></a>Mean and Median</h2>
      <ul>
<li>The mean is sensitive to hte presence of outliers</li>
<li>The median provides a more robust numerical summary of a set of values</li>
<li>To overcome problems with the mean, the notion of a trimmed mean is sometimes used.<ul>
<li>A percentage p between 0 and 100 is specified</li>
<li>The top and bottom (p&#x2F;2)% of the data is thrown out</li>
<li>The mean is then calculated in the normal way</li>
</ul>
</li>
</ul>

        <h2 id="Range"   >
          <a href="#Range" class="heading-link"><i class="fas fa-link"></i></a><a href="#Range" class="headerlink" title="Range"></a>Range</h2>
      <ul>
<li>The simplest measure of spread is the range</li>
<li>Given an attribute x with a set of m values{x1,…,xm}, the range is  defined as</li>
</ul>
<p><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130203926.png"></p>
<ul>
<li>However, using the range to measure the spread can be misleading if <ul>
<li>most of the values are concentrated in a narrow band of values</li>
<li>there are also a relatively small number of more extreme values</li>
</ul>
</li>
</ul>

        <h2 id="Variance"   >
          <a href="#Variance" class="heading-link"><i class="fas fa-link"></i></a><a href="#Variance" class="headerlink" title="Variance"></a>Variance</h2>
      <ul>
<li>The variance of the values of an attribute x is defined as follows:</li>
</ul>
<p><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130203904.png"></p>
<ul>
<li>The standard deviation, which is the square root of the variance, is denoted as <img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130203800.png"></li>
</ul>

        <h1 id="Multivariate-summary-statistics"   >
          <a href="#Multivariate-summary-statistics" class="heading-link"><i class="fas fa-link"></i></a><a href="#Multivariate-summary-statistics" class="headerlink" title="Multivariate summary statistics"></a>Multivariate summary statistics</h1>
      <ul>
<li><p>The mean or median of a data set that consists of several attributes can be obtained by computin the mean or median separately for each attribute</p>
</li>
<li><p>Given a data set, the mean of the data objects is given by :<br><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130203737.png"></p>
</li>
<li><p>For multivariate data, the spread of the data is most commonly captured by the covariance matrix C.</p>
</li>
<li><p>The uv-th entry Cuv is the covariance of the u-th and v-th attributes of the data.<br><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204357.png"></p>
</li>
<li><p>This covariance is given by<br><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130204426.png"></p>
</li>
<li><p>The covariance of two attributes is a measure of the degree to which two attributes vary together </p>
</li>
<li><p>this measure depends on the magnitudes of the variables</p>
</li>
<li><p>In view of this, we perform the following operation on the covariance to obtain the correlation coeffient ruv.<br><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130205356.png"></p>
</li>
<li><p><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130205427.png"> are the standard deviations of xu and xv respectively</p>
</li>
<li><p>The range of ruv is form -1 to 1</p>
</li>
</ul>

        <h1 id="Data-visualization"   >
          <a href="#Data-visualization" class="heading-link"><i class="fas fa-link"></i></a><a href="#Data-visualization" class="headerlink" title="Data visualization"></a>Data visualization</h1>
      <ul>
<li>The motivation of using data visualization is that people can quickly absorb large amounts of visual information and find patterns in it.</li>
<li>We consider the following data visualizaiton techniques<ul>
<li>Histogram</li>
<li>Scatter plot</li>
</ul>
</li>
</ul>

        <h2 id="Histogram"   >
          <a href="#Histogram" class="heading-link"><i class="fas fa-link"></i></a><a href="#Histogram" class="headerlink" title="Histogram"></a>Histogram</h2>
      <ul>
<li>A histogram is a plot that displays the distribution of attribute values by<ul>
<li>dividing the possible values into bins and</li>
<li>showing the number of objects that fall into each bin</li>
</ul>
</li>
<li>Each bin is represented by one bar</li>
<li>The area of each bar is proportional to the number of values that fall into the corresponding range<br><img src="https://raw.githubusercontent.com/LemonKAI/image/main/20230130210104.png"></li>
</ul>

        <h2 id="Scatter-plot"   >
          <a href="#Scatter-plot" class="heading-link"><i class="fas fa-link"></i></a><a href="#Scatter-plot" class="headerlink" title="Scatter plot"></a>Scatter plot</h2>
      <ul>
<li>A scatter plot can graphically show the realtionship between two attributes.</li>
<li>In particular, it can be  used to judge the degree of linear correlation of the attributes.</li>
</ul>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文結束，感謝您的閱讀 ------</div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://lemonkai.github.io/tags/CS3481/">CS3481</a></span><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://lemonkai.github.io/tags/Fundamental-Data-Science/">Fundamental Data Science</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2023/01/30/CS3481-Lecture-3/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">CS3481-Lecture-3</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/2023/01/13/CS4486-Lecture-1/"><span class="paginator-prev__text">CS4486-Lecture-1</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div><div class="comments" id="comments"><div id="utterances-container"></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目錄</span><span class="sidebar-nav-ov">本站概覽</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Data"><span class="toc-number">1.</span> <span class="toc-text">
          Data</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Attribute"><span class="toc-number">2.</span> <span class="toc-text">
          Attribute</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Different-types-of-attributes"><span class="toc-number">3.</span> <span class="toc-text">
          Different types of attributes</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Nominal"><span class="toc-number">3.1.</span> <span class="toc-text">
          Nominal</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ordinal"><span class="toc-number">3.2.</span> <span class="toc-text">
          Ordinal</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Interval"><span class="toc-number">3.3.</span> <span class="toc-text">
          Interval</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ratio"><span class="toc-number">3.4.</span> <span class="toc-text">
          Ratio</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Discrete"><span class="toc-number">3.5.</span> <span class="toc-text">
          Discrete</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Continuous"><span class="toc-number">3.6.</span> <span class="toc-text">
          Continuous</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Types-of-data-sets"><span class="toc-number">4.</span> <span class="toc-text">
          Types of data sets</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Record-data"><span class="toc-number">4.1.</span> <span class="toc-text">
          Record data</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Transaction-or-market-basket-data"><span class="toc-number">4.2.</span> <span class="toc-text">
          Transaction or market basket data</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-matrix"><span class="toc-number">4.3.</span> <span class="toc-text">
          Data matrix</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sparse-data-matrix"><span class="toc-number">4.4.</span> <span class="toc-text">
          Sparse data matrix</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-quality"><span class="toc-number">4.5.</span> <span class="toc-text">
          Data quality</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-quality-Missing-values"><span class="toc-number">4.6.</span> <span class="toc-text">
          Data quality: Missing values</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-preprocessing"><span class="toc-number">4.7.</span> <span class="toc-text">
          Data preprocessing</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Aggregation-%E8%81%9A%E5%90%88"><span class="toc-number">4.7.1.</span> <span class="toc-text">
          Aggregation(聚合)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sampling"><span class="toc-number">4.7.2.</span> <span class="toc-text">
          Sampling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dimensionality-reduction"><span class="toc-number">4.7.3.</span> <span class="toc-text">
          Dimensionality reduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Feature-subset-selection"><span class="toc-number">4.7.4.</span> <span class="toc-text">
          Feature subset selection</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Embedded-approaches"><span class="toc-number">4.7.4.1.</span> <span class="toc-text">
          Embedded approaches</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Filter-approaches"><span class="toc-number">4.7.4.2.</span> <span class="toc-text">
          Filter approaches</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Wrapper-approaches"><span class="toc-number">4.7.4.3.</span> <span class="toc-text">
          Wrapper approaches</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Discretization"><span class="toc-number">4.8.</span> <span class="toc-text">
          Discretization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Normalization"><span class="toc-number">4.9.</span> <span class="toc-text">
          Normalization</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Similarity-and-dissimilarity"><span class="toc-number">5.</span> <span class="toc-text">
          Similarity and dissimilarity</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Dissimilarity-between-attribute-values"><span class="toc-number">5.1.</span> <span class="toc-text">
          Dissimilarity between attribute values</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Nominal-1"><span class="toc-number">5.1.1.</span> <span class="toc-text">
          Nominal</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Ordinal-1"><span class="toc-number">5.1.2.</span> <span class="toc-text">
          Ordinal</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Interval-x2F-Ratio"><span class="toc-number">5.1.3.</span> <span class="toc-text">
          Interval&#x2F;Ratio</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Distance"><span class="toc-number">6.</span> <span class="toc-text">
          Distance</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Summary-statistics"><span class="toc-number">7.</span> <span class="toc-text">
          Summary statistics</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Realtive-frequency-and-the-mode"><span class="toc-number">7.1.</span> <span class="toc-text">
          Realtive frequency and the mode</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Mean"><span class="toc-number">7.2.</span> <span class="toc-text">
          Mean</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Median"><span class="toc-number">7.3.</span> <span class="toc-text">
          Median</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Mean-and-Median"><span class="toc-number">7.4.</span> <span class="toc-text">
          Mean and Median</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Range"><span class="toc-number">7.5.</span> <span class="toc-text">
          Range</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Variance"><span class="toc-number">7.6.</span> <span class="toc-text">
          Variance</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Multivariate-summary-statistics"><span class="toc-number">8.</span> <span class="toc-text">
          Multivariate summary statistics</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Data-visualization"><span class="toc-number">9.</span> <span class="toc-text">
          Data visualization</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Histogram"><span class="toc-number">9.1.</span> <span class="toc-text">
          Histogram</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scatter-plot"><span class="toc-number">9.2.</span> <span class="toc-text">
          Scatter plot</span></a></li></ol></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.svg" alt="avatar"></div><p class="sidebar-ov-author__text">Seize the Day</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">8</div><div class="sidebar-ov-state-item__name">歸檔</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">7</div><div class="sidebar-ov-state-item__name">分類</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">8</div><div class="sidebar-ov-state-item__name">標籤</div></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">你已閱讀了 </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2023</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>KAI</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script>function loadUtterances() {
  var d = document, s = d.createElement('script');
  var container = d.getElementById('utterances-container');

  if (!container) {
    return;
  }
  s.src = 'https://utteranc.es/client.js';
  s.setAttribute('repo', 'LemonKAI/KAIBlogComment');
  s.setAttribute('issue-term', 'title');
  s.setAttribute('label', 'utterances');
  s.setAttribute('theme', 'github-light');
  s.setAttribute('crossorigin', 'anonymous');
  s.setAttribute('async', '');
  if (false) {
    s.setAttribute('data-pjax-rm', '');
  }
  container.append(s);
}

if (false) {
  loadUtterances();
} else {
  window.addEventListener('DOMContentLoaded', loadUtterances, false);
}</script><script src="/js/utils.js?v=2.8.0"></script><script src="/js/stun-boot.js?v=2.8.0"></script><script src="/js/scroll.js?v=2.8.0"></script><script src="/js/header.js?v=2.8.0"></script><script src="/js/sidebar.js?v=2.8.0"></script></body></html>